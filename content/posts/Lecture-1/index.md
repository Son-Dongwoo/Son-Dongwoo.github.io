+++
date = '2025-02-05T01:10:32+09:00'
draft = false
title = 'Lecture 1, Introduction'

tags = ["Deep Reinforcement Learning"]
description = "UC Berkeleyì˜ CS 285 ê°•ì˜ì¸ Deep Reinforcement Learningì˜ Lecture 1 ì •ë¦¬"

UseHugoToc = true
showtoc = true
tocopen = false

[cover]
image = "images/cover.webp"  # ê°™ì€ í´ë” ë‚´ ì´ë¯¸ì§€ ì‚¬ìš©
relative = true  # when using page bundles set this to true, í˜ì´ì§€ ë²ˆë“¤ ë‚´ë¶€ ì´ë¯¸ì§€ ì‚¬ìš©
+++

> ê°•ì˜ ìë£Œ: [UC Berkeley - Deep Reinforcement Learning](https://rail.eecs.berkeley.edu/deeprlcourse/)<br>ê°•ì˜ ì˜ìƒ: [Youtube Link](https://www.youtube.com/playlist?list=PL_iWQOsE6TfVYGEGiAOMaOzzv41Jfm_Ps)
> 

- ê°•í™” í•™ìŠµì€ **ì‚¬ëŒì´ ìƒê°í•˜ì§€ ëª»í•˜ëŠ” ìƒˆë¡œìš´ í•´ê²°ì±…**ì„ ì œì‹œí•  ìˆ˜ ìˆë‹¤. ê·¸ë ‡ê¸°ì— ê°•í™” í•™ìŠµì€ ê³µë¶€í•  ê°€ì¹˜ê°€ ì¶©ë¶„í•˜ë‹¤.

- ê°•í™” í•™ìŠµì€ 2ê°€ì§€ ì˜ë¯¸ë¡œ ì •ì˜ë˜ë©°, ê° ë‚´ìš©ì€ ë¶„ë¦¬ëœ ì •ì˜ì´ë‹¤.
    1. í•™ìŠµ ê¸°ë°˜ ì˜ì‚¬ ê²°ì •ì„ ìœ„í•œ ìˆ˜í•™ì  í˜•ì‹ ì£¼ì˜ 
        
        â†’ Mathematical formalism for learning-based decision making
        
    2. ê²½í—˜ìœ¼ë¡œë¶€í„° ì˜ì‚¬ ê²°ì •ê³¼ ì œì–´ë¥¼ í•™ìŠµí•˜ëŠ” ì ‘ê·¼ ë°©ì‹
        
        â†’ Approach for learning decision making and control from experience
        

- ì§€ë„ í•™ìŠµê³¼ ê°•í™” í•™ìŠµì˜ ì°¨ì´
    
    
    | ì§€ë„ í•™ìŠµ (Usually assumes) | ê°•í™” í•™ìŠµ |
    | --- | --- |
    | i.i.d. data | Data is **not** i.i.d.<br>â†’ previous outputs influence future inputs! |
    | known ground truth outputs in training | Ground truth answer is not known, only know if we succeeded or failed<br>â†’ more generally, we know the reward |

<aside style="border-radius: var(--radius); background:var(--code-bg); padding:5px; border-left:5px solid #f1c40f;">  

ğŸ’¡What is **i.i.d. data (independent and identically distributed)**?  
- **Independent (ë…ë¦½ì„±):** ê° ë°ì´í„° ìƒ˜í”Œì€ ì„œë¡œ ë…ë¦½ì ì´ë‹¤. ì¦‰, í•œ ìƒ˜í”Œì´ ë‹¤ë¥¸ ìƒ˜í”Œì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ”ë‹¤.
- **Identically Distributed (ë™ì¼ ë¶„í¬):** ëª¨ë“  ë°ì´í„° ìƒ˜í”Œì€ ë™ì¼í•œ í™•ë¥  ë¶„í¬ì—ì„œ ì¶”ì¶œëœë‹¤. ì´ëŠ” ë°ì´í„°ê°€ ì¼ì •í•œ ë¶„í¬ë¥¼ ë”°ë¥´ê³  ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
</aside>

- rewardëŠ” scalar ê°’!

- ê°•í™” í•™ìŠµì€ Complex physical tasksë¥¼ ì˜í•œë‹¤.

- ë¦¬ì²˜ë“œ ì„œíŠ¼ì˜ **[The Bitter Lesson](http://incompleteideas.net/IncIdeas/BitterLesson.html)** ì½ì–´ë³´ê¸°
    - Learning: use data to extract patterns (Deep Learning)
    - Search: use computation to extract inferences (Optimization)

- Imitation Learningì€ ë‹¨ìˆœíˆ ê·¼ìœ¡ì˜ ì›€ì§ì„ì„ ë”°ë¼í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ê·¸ í–‰ë™ì˜ ëª©ì ì„ ì´í•´í•˜ê³  ì—ì´ì „íŠ¸ê°€ ë…ì°½ì ìœ¼ë¡œ í–‰ë™í•˜ëŠ” ê²ƒì´ ì¸ìƒì ì´ë‹¤.